{% set name = "apache-airflow-providers-apache-hdfs" %}
{% set version = "3.0.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/apache-airflow-providers-apache-hdfs-{{ version }}.tar.gz
  sha256: 4cc3e5e2cedfae67e599106d08e83686f68c35ba845819a0d7da96f0678ef45f

build:
  script: {{ PYTHON }} -m pip install . -vv
  number: 0
  skip: True  # [py<37]
  skip: True  # [linux and s390x]
  skip: True  # [win]

requirements:
  host:
    - python
    - pip
    - setuptools

  run:
    - python
    - apache-airflow >=2.2.0
    # conda python-hdfs package includes dependencies for avro, dataframe, and kerberos extras
    - python-hdfs >=2.0.4
    - snakebite-py3

test:
  requires:
    - pip
  imports:
    - airflow.providers.apache.hdfs
    - airflow.providers.apache.hdfs.hooks
  commands:
    - pip check

about:
  home: https://airflow.apache.org/
  summary: Provider for Apache Airflow. Implements apache-airflow-providers-apache-hdfs package
  license: Apache-2.0
  license_file:
    - LICENSE
    - NOTICE
  license_family: Apache
  doc_url: https://airflow.apache.org/docs/apache-airflow-providers-apache-hdfs/stable/index.html
  dev_url: https://github.com/apache/airflow/

extra:
  recipe-maintainers:
    - xylar
